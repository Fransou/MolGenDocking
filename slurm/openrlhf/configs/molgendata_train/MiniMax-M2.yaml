# Configuration for MolGenData batch inference
### MODEL SPECIFIC CONFIGURATION
pretrain: /scratch/fransou/MiniMaxAI/MiniMax-M2
max_new_tokens: 32768
top_p: 0.95
temperature: 1.0
output_path: /scratch/fransou/MolGenOutput/molgendata_train/MiniMax-M2/out_{iter}
### DATASET SPECIFIC CONFIGURATION
best_of_n: 16
rollout_batch_size: 100
### COMMON CONFIGURATION
dataset: /scratch/fransou/MolGenData/molgendata/train_data/train_prompts_boxed.jsonl
eval_task: generate_vllm
max_len: 4096
zero_stage: 3
bf16: true
apply_chat_template: true
input_key: messages
label_key: meta
system_prompt: system_prompts/vanilla_boxed.json
tp_size: 4
