# Configuration for MolGenData batch inference
### MODEL SPECIFIC CONFIGURATION
pretrain: /scratch/fransou/Qwen/Qwen3-Next-80B-A3B-Thinking
max_new_tokens: 16384
top_p: 0.95
temperature: 0.6
output_path: /scratch/fransou/MolGenOutput/property_prediction/Qwen3Next_thinking/out_{iter}
### DATASET SPECIFIC CONFIGURATION
best_of_n: 5
rollout_batch_size: 15000
### COMMON CONFIGURATION
dataset: /scratch/fransou/MolGenData/property_prediction/eval_prompts_boxed.jsonl
eval_task: generate_vllm
max_len: 4096
zero_stage: 3
bf16: true
apply_chat_template: true
input_key: messages
label_key: meta
system_prompt: system_prompts/vanilla.json
tp_size: 4
