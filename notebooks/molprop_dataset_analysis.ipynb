{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "a3fa849b551cd4e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from mol_gen_docking.data.pdb_uniprot.target_naming import fetch_uniprot_id_from_pdbid\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "5d701ee9a7d07a38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompts",
   "id": "5543430f7c9981a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from mol_gen_docking.data.pydantic_dataset import read_jsonl\n",
    "from pathlib import Path\n",
    "\n",
    "def load(path:str):\n",
    "    data = read_jsonl(Path(path))\n",
    "    return [line.conversations[0].meta for line in data]\n",
    "\n",
    "def get_df(data_d):\n",
    "    df = pd.DataFrame(data_d)\n",
    "    df= df.explode([\"properties\", \"objectives\", \"target\", \"smiles\"]).reset_index(drop=True)\n",
    "    df[\"origin\"] = df[\"properties\"].apply(lambda x: x.split(\"/\")[0])\n",
    "    df[\"task\"] = df[\"properties\"].apply(lambda x: x.split(\"/\")[1])\n",
    "    return df\n",
    "\n",
    "data_dir = \"data/polaris\"\n",
    "types = [\"novartis\", \"polaris\", \"tdcommons\", \"asap-discovery\", \"biogen\"]\n",
    "\n",
    "\n",
    "data = []\n",
    "for d in types:\n",
    "    directory = Path(os.path.join(data_dir, d))\n",
    "    for file_path in directory.rglob('*train.jsonl'):\n",
    "        data.append(get_df(load(file_path)))\n",
    "        data[-1][\"dataset\"] =\"/\".join(str(file_path).split(\"/\")[3:-1])\n",
    "\n",
    "df = pd.concat(data)\n",
    "df"
   ],
   "id": "e026221017a2ab0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "\n",
    "mols = [Chem.MolFromSmiles(smi) for smi in tqdm(df.smiles.unique())]\n",
    "scaffolds_list = [MurckoScaffold.GetScaffoldForMol(mol) for mol in tqdm(mols)]\n"
   ],
   "id": "5bbfe5b9874ef135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "scaffolds = {}\n",
    "for smi, scaff in zip(df.smiles.unique(), tqdm(scaffolds_list)):\n",
    "    if scaff.GetNumAtoms() <= 6:\n",
    "        scaffolds[smi] = \"n/a\"\n",
    "    else:\n",
    "        scaffolds[smi] = Chem.MolToSmiles(scaff)\n",
    "df[\"scaffold\"] = df.smiles.map(scaffolds)"
   ],
   "id": "9efc00dca2cfacd5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "size = df.groupby(\"dataset\").size().sort_values(ascending=False)\n",
    "df[\"task size\"] =df.dataset.map(size.to_dict())\n",
    "palette = {\n",
    "    origin: sns.color_palette(\"colorblind\", n_colors=10)[i] for i,origin in enumerate(df.origin.unique())\n",
    "}\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize = (12,3), gridspec_kw = {\n",
    "    'width_ratios':[df[df.objectives == \"regression\"].dataset.nunique()/df.dataset.nunique(), df[df.objectives == \"classification\"].dataset.nunique()/df.dataset.nunique()],\n",
    "}, sharey=True)\n",
    "fig.subplots_adjust(wspace=0.01)\n",
    "sns.histplot(df[df.objectives == \"regression\"].sort_values(\"task size\"), x=\"dataset\", hue=\"origin\",ax = axes[0], palette=palette)\n",
    "axes[0].set_title(\"Regression\")\n",
    "sns.histplot(df[df.objectives == \"classification\"].sort_values(\"task size\"), x=\"dataset\", hue=\"origin\",ax = axes[1], palette=palette, legend=False)\n",
    "axes[1].set_title(\"Classification\")\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "fig.savefig(\"mol_prop_task_size.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "742b782fdf0d2053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rdkit.Chem import Draw\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "fig, ax = plt.subplots(figsize=(14, 3))\n",
    "\n",
    "count = df[df.scaffold.apply(len)>3].groupby(\"scaffold\").size().sort_values(ascending=False)\n",
    "scaffs_to_keep = count.index.tolist()[:30]\n",
    "\n",
    "\n",
    "df[\"n_scaff\"] = df.scaffold.map(count.to_dict())\n",
    "df_top = df[df.scaffold.isin(scaffs_to_keep)]\n",
    "df_top = df_top.sort_values(\"n_scaff\", ascending=False)\n",
    "sns.histplot(df_top, x=\"scaffold\", hue=\"origin\",multiple=\"stack\", log_scale=False, ax=ax)\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xlim(-0.5,29.5)\n",
    "ax.set_xticks([])  # remove default labels\n",
    "\n",
    "scaff_to_img = {}\n",
    "for scaff in scaffs_to_keep:\n",
    "    mol = Chem.MolFromSmiles(scaff)\n",
    "    if mol:\n",
    "        img = Draw.MolToImage(mol, size=(80, 80))\n",
    "        scaff_to_img[scaff] = img\n",
    "\n",
    "# Add images as tick labels\n",
    "for i, scaff in enumerate(scaffs_to_keep):\n",
    "    if scaff in scaff_to_img:\n",
    "        imagebox = OffsetImage(scaff_to_img[scaff], zoom = 0.2)\n",
    "        ab = AnnotationBbox(imagebox, (i, 0), frameon=True, box_alignment=(0.5, 1.4))\n",
    "        ax.add_artist(ab)\n",
    "\n",
    "\n",
    "fig.savefig(\"mol_prop_scaff.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "521b06f45cf0ba86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "from rdkit.Chem import DataStructs\n",
    "from rdkit import RDLogger\n",
    "\n",
    "RDLogger.DisableLog(\"rdApp.*\")\n",
    "\n",
    "def get_tanimoto_dist_between_datasets(df, dataset0, dataset1,radius=2, n_bits=1024, agg_fns = [np.mean]):\n",
    "    mols = [\n",
    "        [Chem.MolFromSmiles(smi) for smi in df[df.dataset == dataset0].smiles.unique()],\n",
    "        [Chem.MolFromSmiles(smi) for smi in df[df.dataset == dataset1].smiles.unique()]\n",
    "    ]\n",
    "    fps_ = [\n",
    "        [GetMorganFingerprintAsBitVect(m, radius, nBits=n_bits) for m in mol if m is not None]\n",
    "        for mol in mols\n",
    "    ]\n",
    "    sims = np.zeros((len(fps_[0]), len(fps_[1])))\n",
    "    for i,fp0 in enumerate(fps_[0]):\n",
    "        sims[i,:] = DataStructs.BulkTanimotoSimilarity(fp0, fps_[1])\n",
    "    output = [(np.mean(agg_fn(sims))+ np.mean(agg_fn(sims.transpose())))/2 for agg_fn in agg_fns]\n",
    "    return output\n"
   ],
   "id": "8764220c0d4894f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_simi = []\n",
    "pbar = tqdm(total=df.dataset.nunique()*(df.dataset.nunique()+1)//2)\n",
    "agg_fns = [\n",
    "    lambda arr: np.max(arr, axis=1),\n",
    "    lambda arr: np.quantile(arr,0.99, axis=1),\n",
    "    lambda arr: np.quantile(arr,0.9, axis=1),\n",
    "    lambda arr: (arr>=0.6).mean(axis=1),\n",
    "    lambda arr: (arr>=0.7).mean(axis=1),\n",
    "    lambda arr: (arr>=0.8).mean(axis=1),\n",
    "]\n",
    "agg_fns_name = [\n",
    "    \"max\",\n",
    "    \"99% quantile\",\n",
    "    \"90% quantile\",\n",
    "    \"Prop. over 0.6\",\n",
    "    \"Prop. over 0.7\",\n",
    "    \"Prop. over 0.8\",\n",
    "]\n",
    "\n",
    "for i, dataset0 in enumerate(df.dataset.unique()):\n",
    "    for dataset1 in df.dataset.unique()[i:]:\n",
    "        sims_l = get_tanimoto_dist_between_datasets(df, dataset0, dataset1, agg_fns=agg_fns)\n",
    "        for sims, name in zip(sims_l, agg_fns_name):\n",
    "            df_simi.append([dataset0, dataset1, sims, name])\n",
    "            df_simi.append([dataset1, dataset0, sims, name])\n",
    "        pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "df_simi = pd.DataFrame(df_simi, columns=[\"dataset0\", \"dataset1\", \"value\", \"agg_fn_name\"])"
   ],
   "id": "6cd5569c109a60a9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df_simi",
   "id": "b3edc3e0f306d60c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.cluster.hierarchy import linkage\n",
    "for agg_name in agg_fns_name:\n",
    "    data = df_simi[df_simi.agg_fn_name == agg_name].pivot_table(values=\"value\", columns=\"dataset0\", index=\"dataset1\")\n",
    "    row_linkage = linkage(data, method='ward')\n",
    "\n",
    "    cg = sns.clustermap(data, row_linkage=row_linkage, col_linkage=row_linkage, figsize=(6,6))\n",
    "    plt.title(f\"agg_fn_name = {agg_name}\")\n",
    "\n",
    "    cg.ax_row_dendrogram.set_visible(False) #suppress row dendrogram\n",
    "    cg.ax_col_dendrogram.set_visible(False) #suppress column dendrogram\n",
    "    plt.show()\n"
   ],
   "id": "bd2258720d4d77d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "agg_name = \"max\"\n",
    "data = df_simi[df_simi.agg_fn_name == agg_name].pivot_table(values=\"value\", columns=\"dataset0\", index=\"dataset1\")\n",
    "row_linkage = linkage(data, method='ward')\n",
    "\n",
    "cg = sns.clustermap(data, row_linkage=row_linkage, col_linkage=row_linkage, vmax = 1,cbar_pos=(0.05, 0.3, 0.055, 0.5))\n",
    "\n",
    "\n",
    "cg.ax_row_dendrogram.set_visible(False) #suppress row dendrogram\n",
    "cg.ax_col_dendrogram.set_visible(False) #suppress column dendrogram\n",
    "\n",
    "cg.savefig(\"tanimoto_mol_prop.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "409626e9de85197",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "ed16e6e9ca618a9d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "440f72741e69f337",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
