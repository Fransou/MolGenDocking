{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ],
   "id": "2ea09c2f4e31d3bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from rdkit import Chem\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from notebooks.utils import *"
   ],
   "id": "9d38af1b0b4b0c70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading",
   "id": "c13199fbd168f887"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MOLSTRAL_PATH = Path(\"MolGenOutput/test_ood\")\n",
    "FIG_PATH = \"/home/philippe/-Philippe-MolGenDocking/Figures/Results/MolGen\"\n",
    "os.makedirs(FIG_PATH, exist_ok=True)\n",
    "\n",
    "files = [f for d in MOLSTRAL_PATH.iterdir() for f in d.iterdir() if \"error\" not in str(f) and str(f).endswith(\"scored.jsonl\")]\n",
    "files = sorted(files)\n",
    "\n",
    "print(\"Total files:\", len(files))\n",
    "df = load_molgen_results(files[:])\n",
    "\n",
    "\n",
    "sub_sample_prompts = df[df.model == \"MiniMax-M2_\"].prompt_id.unique()[:]\n",
    "df = df[df.prompt_id.isin(sub_sample_prompts)]\n",
    "\n",
    "sub_sample_prompts = df[df.model == \"Qwen3-Next-80B-A3B-Thinking_\"].prompt_id.unique()[:]\n",
    "df = df[df.prompt_id.isin(sub_sample_prompts)]"
   ],
   "id": "565815a1fa1d4d41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Validity Plot",
   "id": "f0ca07bd07e05f1c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cmap = {\n",
    "    \"valid\": \"seagreen\",\n",
    "    \"no valid SMILES\": \"gold\",\n",
    "    \"multiple SMILES\": \"darkorange\",\n",
    "    \"no SMILES\": \"brown\",\n",
    "    \"no answer\": \"red\"\n",
    "}\n",
    "\n",
    "ax = sns.histplot(data=df, x=\"Model\", hue=\"valid\", multiple=\"stack\", stat=\"count\", palette= cmap, hue_order=list(cmap.keys()))\n",
    "# rotate x labels\n",
    "max_count = 128_000\n",
    "ax.set_ylim(0, max_count)\n",
    "\n",
    "yticks = np.linspace(0, max_count, 6)\n",
    "ax.set_yticks(yticks)\n",
    "ax.set_yticklabels([f\"{int(y / max_count * 100)}%\" for y in yticks])\n",
    "_ = plt.xticks(rotation=45, ha='right')\n",
    "# Replace y_ticks with percentages from 0 to 100\n",
    "\n",
    "plt.savefig(f\"{FIG_PATH}/validity.pdf\", bbox_inches='tight')"
   ],
   "id": "51971644995952e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Rank Heatmaps",
   "id": "e33bca8de8b5fbdc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "topk_dfs = []\n",
    "ROLLOUTS_AT_K = {\n",
    "    1: [5, 10, 50],\n",
    "    5: [10, 25, 50],\n",
    "    10: [25, 50, 100],\n",
    "}\n",
    "pbar = tqdm(total=sum([len(ROLLOUTS_AT_K[k]) for k in ROLLOUTS_AT_K]))\n",
    "\n",
    "for k in tqdm(ROLLOUTS_AT_K):\n",
    "    roll_values = ROLLOUTS_AT_K[k]\n",
    "    stopk_dfs = []\n",
    "    for r in roll_values:\n",
    "        topdf = df[df.prompt_id.isin(sub_sample_prompts[:])].groupby(\n",
    "            [\"Model\", \"prompt_id\"]\n",
    "        ).apply(\n",
    "            aggregate_molgen_fn(\"topk\", k=k, n_rollout=r)\n",
    "        ).to_frame().rename(columns={0:f\"{r}\"}).reset_index()\n",
    "        stopk_dfs.append(\n",
    "            topdf\n",
    "        )\n",
    "        pbar.update(1)\n",
    "    topk_df = pd.concat(stopk_dfs).reset_index(drop=True)\n",
    "    topk_df[\"k\"] = k\n",
    "    topk_df = topk_df.melt(id_vars=[\"prompt_id\",\"Model\", \"k\"], value_vars=[str(k) for k in roll_values], var_name=\"n_rollout\", value_name= \"top-k\")\n",
    "    topk_df[\"n_rollout\"] = topk_df[\"n_rollout\"].apply(int)\n",
    "    topk_dfs.append(topk_df)\n",
    "\n",
    "pbar.close()\n",
    "topk_df = pd.concat(topk_dfs).reset_index(drop=True)\n",
    "topk_df[\"rank\"] = topk_df.groupby([\"prompt_id\", \"k\", \"n_rollout\"])[\"top-k\"].rank(ascending=False)"
   ],
   "id": "be4bef0fb92debc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sort_prompt_ids(sub_df, y_order, r_max=2):\n",
    "    x_order = []\n",
    "    for model in y_order:\n",
    "        first_rank = sub_df[(sub_df.Model == model) & (sub_df[\"rank\"] == r_max-1)].prompt_id.tolist()\n",
    "        # sort_first_rank = sub_df[(sub_df.Model == y_order[0]) & (sub_df.prompt_id.isin(first_rank))].sort_values(by=\"rank\")\n",
    "        # first_rank = sort_first_rank.prompt_id.tolist()\n",
    "        x_order.append(first_rank)\n",
    "        maybe_rank = sub_df[(sub_df.Model == model) & (sub_df[\"rank\"] < r_max) & (sub_df[\"rank\"] > r_max-1)]\n",
    "        maybe_rank = [r for r in maybe_rank.prompt_id.tolist() if r not in x_order]\n",
    "        x_order.append(maybe_rank)\n",
    "    return x_order\n",
    "\n",
    "def sort_recursive_prompts(sub_df, y_order, to_sort, r_max):\n",
    "    if len(to_sort) <=1:\n",
    "        return to_sort\n",
    "    if r_max >= 8:\n",
    "        return to_sort\n",
    "    groups = sort_prompt_ids(sub_df, y_order, r_max=r_max)\n",
    "    return sum(\n",
    "        [sort_recursive_prompts(sub_df[sub_df.prompt_id.isin(g)], y_order, g, r_max +1) for g in groups],\n",
    "        []\n",
    "    )"
   ],
   "id": "7068cbc333eb97d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_order = topk_df.groupby(\"Model\")[\"rank\"].mean().sort_values().index.tolist()\n",
    "\n",
    "full_ratio = 3.2\n",
    "avg_ratio = 0.5\n",
    "cbar_ratio = 0.1\n",
    "\n",
    "for k in ROLLOUTS_AT_K:\n",
    "    roll_values = ROLLOUTS_AT_K[k]\n",
    "\n",
    "    fig, axes_k = plt.subplots(1, 7, figsize=(10,3), gridspec_kw={\"width_ratios\":[full_ratio, avg_ratio] * len(roll_values) +[0.1], \"wspace\":0.05})\n",
    "\n",
    "    for i_n,n_rolls in enumerate(tqdm(roll_values)):\n",
    "        sub_df = topk_df[(topk_df.k == k) & (topk_df.n_rollout==n_rolls)]\n",
    "        x_order = sort_recursive_prompts(sub_df, y_order, sub_df.prompt_id.unique().tolist(), r_max=2)\n",
    "        heat_kwargs = {\n",
    "            \"cmap\":\"magma_r\",\n",
    "            \"vmin\":1,\n",
    "            \"vmax\":len(y_order),\n",
    "        }\n",
    "        heatmap_df = sub_df.pivot_table(index=\"Model\", columns=[\"prompt_id\"], values=\"rank\")\n",
    "        heatmap_df = heatmap_df.reindex(index=y_order, columns=x_order)\n",
    "        if i_n == 0:\n",
    "            heat_kwargs[\"yticklabels\"] = True\n",
    "        else:\n",
    "            heat_kwargs[\"yticklabels\"] = False\n",
    "        axes = axes_k[i_n*2:(i_n*2)+2 + int(i_n == len(roll_values) - 1)]\n",
    "\n",
    "        sns.heatmap(heatmap_df, cbar=None, ax = axes[0], **heat_kwargs)\n",
    "        sns.heatmap(heatmap_df.mean(1).to_frame(), cbar = None, ax = axes[1], annot = True, fmt=\".1f\", **heat_kwargs)\n",
    "\n",
    "        axes[0].set_title(f\"$n_r=${n_rolls}\")\n",
    "        for ax in axes:\n",
    "            ax.set_xlabel(\"\")\n",
    "            ax.set_ylabel(\"\")\n",
    "            # remove xticks\n",
    "        axes[0].set_xticks([])\n",
    "        # set xtick label to \"avg\" for the second heatmap\n",
    "        axes[1].set_xticks([0.5])\n",
    "        axes[1].set_xticklabels([\"avg\"])\n",
    "        axes[1].set_yticks([])\n",
    "\n",
    "        # colorbar for the first heatmap in axes[2]\n",
    "        if len(axes) == 3:\n",
    "            cbar = fig.colorbar(plt.cm.ScalarMappable(cmap=\"magma_r\", norm=plt.Normalize(vmin=1, vmax=len(y_order))), cax=axes[2])\n",
    "            cbar.set_label(\"Rank\")\n",
    "    os.makedirs(f\"{FIG_PATH}/heatmap\", exist_ok=True)\n",
    "    plt.savefig(f\"{FIG_PATH}/heatmap/topk_{k}_ranks_heatmap.pdf\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ],
   "id": "563bcec81eb13bdf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Uniqueness and Diversity Metrics",
   "id": "2805b1971aff1252"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Computations",
   "id": "86e714f93afbd9fb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Compute the uniqueness of the generated smiles in each prompt",
   "id": "c8bd3a6d82e58167"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uniq_df = df[df.validity == 1].groupby([\"Model\", \"prompt_id\"]).agg(\n",
    "    **{f\"{k}\":pd.NamedAgg(column=\"smiles\", aggfunc=aggregate_molgen_fn(\"uniqueness\", k)) for k in list(range(1,100,10))}\n",
    ").reset_index()\n",
    "uniq_df = uniq_df.melt(id_vars=[\"Model\"], value_vars=[str(k) for k in list(range(1,100,10))], var_name=\"n_rollout\")\n",
    "uniq_df[\"n_rollout\"] = uniq_df[\"n_rollout\"].apply(int)"
   ],
   "id": "f90e4a04d461de87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Diversity in each prompt (ecfp4)",
   "id": "215597197ca9992e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fp_fn = fp_name_to_fn(\"ecfp4-2048\")\n",
    "sub_df = df[\n",
    "    (df.validity == 1) & (df.prompt_id.isin(sub_sample_prompts))\n",
    "].drop_duplicates(subset=[\"prompt_id\", \"smiles\"])\n",
    "sub_df[\"fps\"] = sub_df[\"smiles\"].progress_apply(lambda x: fp_fn(Chem.MolFromSmiles(x)))\n",
    "\n",
    "sim_df = sub_df.groupby([\"Model\", \"prompt_id\"]).agg(\n",
    "    **{\n",
    "        f\"{k}\":pd.NamedAgg(\n",
    "            column=\"fps\",\n",
    "            aggfunc=aggregate_molgen_fn(\"diversity\",k, is_fp=True))\n",
    "        for k in [50]\n",
    "    }\n",
    ").reset_index()\n",
    "sim_df = sim_df.melt(id_vars=[\"Model\"], value_vars=[str(k) for k in [50]], var_name=\"n_rollout\")\n",
    "sim_df[\"n_rollout\"] = sim_df[\"n_rollout\"].apply(int)"
   ],
   "id": "dedbed0f0d16b73f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Uniqueness accross prompts",
   "id": "93b9deaa7568698f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "uniqueness_ac_prompts = []\n",
    "\n",
    "def topk_fn(k):\n",
    "    def get_topk(x):\n",
    "        return list(np.pad(x, (0, 100), 'constant', constant_values=None)[:k])\n",
    "    return get_topk\n",
    "\n",
    "def uniqueness_across_prompts(smiles_lists):\n",
    "    smiles_conc = sum(smiles_lists, [])\n",
    "    all_smiles = set(smiles_conc)\n",
    "    return len(all_smiles) / len(smiles_conc)\n",
    "\n",
    "for k in tqdm(range(2,101,10)):\n",
    "    smiles_per_p = df[df.validity == 1].groupby(\n",
    "        [\"Model\", \"prompt_id\"]\n",
    "    ).smiles.apply(topk_fn(k)).reset_index()\n",
    "    uniqueness_ac_prompts.append(\n",
    "        smiles_per_p.groupby(\"Model\").smiles.apply(\n",
    "            uniqueness_across_prompts\n",
    "        ).reset_index().rename(columns={\"smiles\":str(k)})\n",
    "    )\n",
    "\n",
    "uniq_ap_df = pd.concat(\n",
    "    [sdf.set_index(\"Model\") for sdf in uniqueness_ac_prompts], axis = 1\n",
    ").reset_index().melt(id_vars=[\"Model\"], value_vars=[str(k) for k in range(2,101,10)], var_name=\"n_rollout\")\n",
    "uniq_ap_df[\"n_rollout\"] = uniq_ap_df[\"n_rollout\"].apply(int)"
   ],
   "id": "896ee4e41caea26b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Plots",
   "id": "beb1990c4f3da2b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from notebooks.utils import CMAP_MODELS",
   "id": "19e3455d7be0de20",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(9,3), sharey=False, gridspec_kw={\"wspace\":0.4})\n",
    "\n",
    "ax = axes[0]\n",
    "sns.lineplot(uniq_df, x=\"n_rollout\", y=\"value\", hue=\"Model\", ax=ax, legend=True, palette=CMAP_MODELS, hue_order=CMAP_MODELS.keys())\n",
    "ax.set_ylabel(\"Uniqueness-Prompt-wise\")\n",
    "ax.set_xlabel(\"$n_r$\")\n",
    "ax.set_ylim(0,1)\n",
    "ax.set_xlim(5,100)\n",
    "# Move legend below plot\n",
    "ax.legend(bbox_to_anchor=(1.8, -.5), loc='lower center', ncols=4)\n",
    "\n",
    "ax = axes[1]\n",
    "sns.lineplot(uniq_ap_df, x=\"n_rollout\", y=\"value\", hue=\"Model\", ax=ax, legend = False, palette=CMAP_MODELS, alpha=0.8)\n",
    "ax.set_ylabel(\"Uniqueness-Across-Prompts\")\n",
    "ax.set_ylim(0.,1)\n",
    "ax.set_xlim(5,100)\n",
    "ax.set_xlabel(\"$n_r$\")\n",
    "\n",
    "ax = axes[2]\n",
    "x_order = sim_df.groupby(\"Model\")[\"value\"].median().sort_values().index.tolist()\n",
    "sns.boxplot(sim_df, x=\"Model\", y=\"value\", hue=\"Model\", ax=ax, legend = False, order=x_order, palette=CMAP_MODELS,fliersize=0)\n",
    "ax.set_ylabel(\"Diversity-Prompt-wise\")\n",
    "ax.set_xlabel(\"\")\n",
    "ax.set_xticklabels([],)\n",
    "ax.set(ylim=(0.4,1))\n",
    "\n",
    "fig.savefig(f\"{FIG_PATH}/uniqueness_diversity.pdf\", bbox_inches='tight')"
   ],
   "id": "af77a97b04ac61f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Top-k scores",
   "id": "1d2dfa4f21f7c16d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "k_values = [1,5,10,20,30]\n",
    "topk_dfs = []\n",
    "pbar = tqdm(total=sum([len(range(k+1,101,10)) for k in k_values]))\n",
    "\n",
    "for k in k_values:\n",
    "    roll_values = list(range(k+1,101,10))\n",
    "    k_topk_dfs = []\n",
    "    for roll in roll_values:\n",
    "        topdf = df[df.prompt_id.isin(sub_sample_prompts[:])].groupby(\n",
    "            [\"Model\", \"prompt_id\"]\n",
    "        ).apply(\n",
    "            aggregate_molgen_fn(\"topk\", k=k, n_rollout=roll)\n",
    "        ).to_frame().rename(columns={0:f\"{roll}\"}).reset_index()\n",
    "        k_topk_dfs.append(\n",
    "            topdf\n",
    "        )\n",
    "        pbar.update(1)\n",
    "\n",
    "    topk_df = pd.concat(k_topk_dfs).reset_index(drop=True)\n",
    "    topk_df[\"k\"] = k\n",
    "    topk_df = topk_df.melt(id_vars=[\"prompt_id\",\"Model\", \"k\"], value_vars=[str(k) for k in roll_values], var_name=\"n_rollout\", value_name= \"top-k\")\n",
    "    topk_df[\"n_rollout\"] = topk_df[\"n_rollout\"].apply(int)\n",
    "\n",
    "    topk_dfs.append(topk_df)\n",
    "pbar.close()\n",
    "topk_df = pd.concat(topk_dfs).reset_index(drop=True)"
   ],
   "id": "f123009558ab20d1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig,axes = plt.subplots(\n",
    "    1,\n",
    "    topk_df.k.nunique(),\n",
    "    figsize=(3 * topk_df.k.nunique(),3),\n",
    "    sharey=True,\n",
    "    gridspec_kw={\"wspace\":0.1 }\n",
    ")\n",
    "\n",
    "for k, ax in zip(topk_df.k.unique(), axes):\n",
    "    sns.lineplot(topk_df[\n",
    "         topk_df.k == k\n",
    "     ], x=\"n_rollout\", y=\"top-k\", hue=\"Model\", ax=ax, legend = k==30, palette=CMAP_MODELS, hue_order=CMAP_MODELS.keys())\n",
    "    ax.set_ylabel(\"top-k score\")\n",
    "    ax.set_title(f\"k = {k}\")\n",
    "# Move legend of the last axis below plot\n",
    "axes[-1].legend(bbox_to_anchor=(-1.8, -0.55), loc='lower center', ncols=4)\n",
    "\n",
    "fig.savefig(f\"{FIG_PATH}/topk_k_score.pdf\", bbox_inches='tight')"
   ],
   "id": "14f63f1c5b5f1e77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tables for Top-k",
   "id": "7a33375b2b4c9356"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from notebooks.metadata.molgen import MODEL_META",
   "id": "e40199c6110898ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create table with: model_name, size, metric_name, value\n",
    "import re\n",
    "\n",
    "ROLLOUTS_AT_K = {\n",
    "    1: [10, 50,],\n",
    "    5: [10, 50,],\n",
    "    10: [50, 100,],\n",
    "    30: [50, 100,],\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(columns=[\"model\", \"Size\", \"Think.\", \"Metric\", r\"$n_\\text{rollouts}$\", \"Value\"])\n",
    "size_pattern = re.compile(r'(?i)(?:^|[-_])(\\d+\\s*[b])(?:$|[-_])')\n",
    "pbar = tqdm(total=len(df.model.unique())*sum([len(ROLLOUTS_AT_K[k]) for k in ROLLOUTS_AT_K]))\n",
    "\n",
    "for model_name in df.model.unique():\n",
    "    assert any([m in model_name for m in MODEL_META.keys()]), f\"Model {model_name} not found in MODEL_META\"\n",
    "    key = [m for m in MODEL_META.keys() if m in model_name][0]\n",
    "    metadata = MODEL_META[key]\n",
    "    for k in ROLLOUTS_AT_K:\n",
    "        for n_rollout in ROLLOUTS_AT_K[k]:\n",
    "            sub_df = df[df.model == model_name]\n",
    "            sub_df = sub_df.drop_duplicates(subset=[\"prompt_id\", \"smiles\"])\n",
    "            pass_k = sub_df.groupby(\"prompt_id\").apply(\n",
    "                aggregate_molgen_fn(\"topk\",k=k, n_rollout=n_rollout)\n",
    "            ).to_frame().rename(columns={0:str(k)}).reset_index()\n",
    "            if not \"size\" in metadata:\n",
    "                try:\n",
    "                    size = size_pattern.search(model_name).group(1).upper()\n",
    "                except:\n",
    "                    raise ValueError(f\"Size not found for model {model_name}\")\n",
    "            else:\n",
    "                size = metadata[\"size\"]\n",
    "            for i, row in pass_k.iterrows():\n",
    "                thinking = r\"\\CheckmarkBold\" if metadata[\"thinking\"] else r\"\\XSolidBrush\"\n",
    "                chem = r\"\\CheckmarkBold\" if metadata[\"Chem.\"] else r\"\\XSolidBrush\"\n",
    "\n",
    "                table.loc[len(table)] = [\n",
    "                    model_name,\n",
    "                    size,\n",
    "                    thinking,\n",
    "                    # chem,\n",
    "                    f\"top-{k}, $n_r$:\",\n",
    "                    n_rollout,\n",
    "                    row[str(k)]\n",
    "                ]\n",
    "            pbar.update(1)\n"
   ],
   "id": "7713b23275a5ded6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from notebooks.utils.utils import process_model_name\n",
    "\n",
    "table[\"Model\"] = table[\"model\"].apply(lambda x: re.sub(r\"-\\d+(B|b)\", \"\", x).replace(\"-2507\", \"\").replace(\"-A3B\", \"\").replace(\"-Distill\", \"\").replace(\"-it\", \"\").replace(\"Thinking\", \"Think.\").replace(\"DeepSeek-\", \"\").replace(\"-Instruct\", \"\"))\n",
    "\n",
    "MODEL_ORDER = [\n",
    "    \"MiniMax-M2\",\n",
    "    \"Qwen3-Think.\",\n",
    "    \"Qwen3-Next-Think.\",\n",
    "    \"gpt-oss\",\n",
    "    \"R1-Llama\",\n",
    "    \"R1-Qwen\",\n",
    "    \"gemma-3\",\n",
    "    \"Llama-3.3\",\n",
    "    \"ChemDFM-R\",\n",
    "    \"ether0\",\n",
    "    \"ChemDFM-v2.0\",\n",
    "]\n",
    "\n",
    "table[\"N_rolls\"] = table[r\"$n_\\text{rollouts}$\"].apply(lambda x: str(x))\n",
    "table[\"Model\"] = table[\"Model\"].apply(lambda x: x.replace(\"_\", \"\"))\n"
   ],
   "id": "d23ac065de108fc9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "LATEX_PATH = \"/home/philippe/-Philippe-MolGenDocking/tables\"\n",
    "cmap = sns.color_palette(\"vlag\", as_cmap=True)\n",
    "cmap"
   ],
   "id": "2b78a57d6e215052",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from notebooks.utils import PandasTableFormatter\n",
    "\n",
    "def color_map(val: float) -> str:\n",
    "    \"Returns a color based on the value (eg '#FF5733')\"\n",
    "    color = cmap(val)\n",
    "    return f\"rgb({int(color[0]*255)}, {int(color[1]*255)}, {int(color[2]*255)})\"\n",
    "\n",
    "formatter = PandasTableFormatter(\n",
    "    n_decimals = 3, # Number of decimals to keep in the table\n",
    "    aggregation_methods=[\"mean\"], # Aggregation functions to apply to the data\n",
    "    main_subset=0, # Subset of values to bold, here the first column will be bolded corresponding to the mean values, if [0,1] the first two columns will be bolded (independently)\n",
    "    hide_agg_labels=True, # Hide the aggregation column names in the latex\n",
    "    global_agg=False, # Whether to compute global aggregation across all columns (True)\n",
    "    color_mapping =color_map\n",
    ")\n",
    "\n",
    "style = formatter.style(\n",
    "    table, # Dataframe to format\n",
    "    rows= [\"Model\", \"Size\", \"Think.\"], # Rows\n",
    "    cols=[\"Metric\", r\"N_rolls\"], # Columns\n",
    "    values= \"Value\", # Values\n",
    "    highlight_fn= np.nanmax, # Function to use to highlight the values, here the maximum values will be highlighted\n",
    "    props=[\"textbf:--rwrap--latex; underline:--rwrap--latex\", \"underline:--rwrap--latex\", \"underline:--rwrap--latex\",], # Properties to apply to the highlighted values, here the maximum values will be underlined and bolded, the second maximum values will be bolded\n",
    "    special_format_agg = {\n",
    "        \"std\": lambda x: \"\\\\tiny $\\\\pm$\" + x, # Format to apply to the standard deviation values\n",
    "    },\n",
    "    remove_col_names=True,\n",
    "    row_order = MODEL_ORDER\n",
    ")\n",
    "formatter.save_to_latex(\n",
    "    style, f\"{LATEX_PATH}/gen_table.tex\", 0, multicol_align=\"|c|\", hrules=True,\n",
    ")\n",
    "style"
   ],
   "id": "d8479182880a3687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "formatter = PandasTableFormatter(\n",
    "    n_decimals = 3, # Number of decimals to keep in the table\n",
    "    aggregation_methods=[\"mean\", \"std\"], # Aggregation functions to apply to the data\n",
    "    main_subset=0, # Subset of values to bold, here the first column will be bolded corresponding to the mean values, if [0,1] the first two columns will be bolded (independently)\n",
    "    hide_agg_labels=True, # Hide the aggregation column names in the latex\n",
    "    global_agg=False # Whether to compute global aggregation across all columns (True)\n",
    ")\n",
    "\n",
    "style = formatter.style(\n",
    "    table, # Dataframe to format\n",
    "    rows= [\"Model\", \"Size\", \"Think.\"], # Rows\n",
    "    cols=[\"Metric\", r\"N_rolls\"], # Columns\n",
    "    values= \"Value\", # Values\n",
    "    highlight_fn= np.nanmax, # Function to use to highlight the values, here the maximum values will be highlighted\n",
    "    props=[\"font-weight: bold; text-decoration: underline;\", \"text-decoration: underline;\"], # Properties to apply to the highlighted values, here the maximum values will be underlined and bolded, the second maximum values will be bolded\n",
    "    special_format_agg = {\n",
    "        \"std\": lambda x: \"\\\\tiny $\\\\pm$\" + x, # Format to apply to the standard deviation values\n",
    "    },\n",
    "    remove_col_names=True,\n",
    "    row_order = MODEL_ORDER\n",
    ")\n",
    "formatter.save_to_latex(style, f\"{LATEX_PATH}/gen_table_std.tex\", 1, multicol_align=\"|c|\", hrules=True, n_first_cols=2)"
   ],
   "id": "2966abe16f83241f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "376babd5f3b57722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2c2a079636eb20c3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
