{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ],
   "id": "b26e209607609ab2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading",
   "id": "5f681a41577f51c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit import DataStructs\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.cluster.hierarchy import linkage, fcluster\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from notebooks.utils import PandasTableFormatter\n",
    "from mol_gen_docking.evaluation.diversity_aware_top_k import diversity_aware_top_k\n",
    "from notebooks.utils import *\n",
    "\n",
    "FIG_PATH = \"MolGenDocking-latex/Figures/Results/MolProp\"\n",
    "os.makedirs(FIG_PATH, exist_ok=True)\n"
   ],
   "id": "66aa347d05d8ca3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "MOLSTRAL_PATH = Path(\"MolGenOutput/polaris\")\n",
    "\n",
    "files = [f for f in MOLSTRAL_PATH.iterdir() if \"error\" not in str(f) and str(f).endswith(\"scored.jsonl\")]\n",
    "files = [f for f in files if not any(avoid in f.name for avoid in [\"MiniMax\", \"R1\", \"ether0\"])]\n",
    "files = sorted(files)\n",
    "full_df = load_molprop_results(files)"
   ],
   "id": "6d2b47f60b0e556e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "full_df = full_df.groupby([\"Model\", \"prompt_id\", \"Task\"]).head(5)\n",
    "# For each model, drop tasks where not all prompt_ids appear\n",
    "# Get the set of prompt_ids per task (reference)\n",
    "prompt_ids_per_task = full_df.groupby(\"Task\").prompt_id.apply(set)\n",
    "# Get the set of prompt_ids per (Model, Task)\n",
    "prompt_ids_per_model_task = full_df.groupby([\"Model\", \"Task\"]).prompt_id.apply(set)\n",
    "# Check which (Model, Task) combinations have all prompt_ids\n",
    "valid_model_tasks = prompt_ids_per_model_task.reset_index()\n",
    "valid_model_tasks[\"all_prompts\"] = valid_model_tasks.apply(\n",
    "    lambda x: x.prompt_id == prompt_ids_per_task[x.Task], axis=1\n",
    ")\n",
    "valid_model_tasks = valid_model_tasks[valid_model_tasks[\"all_prompts\"]][[\"Model\", \"Task\"]]\n",
    "# Filter using merge (much faster than row-wise apply)\n",
    "full_df = full_df.merge(valid_model_tasks, on=[\"Model\", \"Task\"], how=\"inner\")\n"
   ],
   "id": "cc2648bff4ac891",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_validity_no_numeric_mistake = full_df.groupby([\"Model\", \"prompt_id\", \"Task\", \"objectives\"])[[\"validity\", \"contains_numeric\"]].apply(\n",
    "    lambda x: any(x.validity) or not any(x.contains_numeric)\n",
    ").reset_index().rename(columns={0: \"non-valid-and-numeric\"})\n",
    "\n",
    "df_validity = full_df.groupby([\"Model\", \"prompt_id\", \"Task\", \"objectives\"]).validity.apply(\n",
    "    lambda x: any(x)\n",
    ").reset_index()\n",
    "\n",
    "# Merge to get contains_numeric info\n",
    "df_validity = df_validity.merge(\n",
    "    df_validity_no_numeric_mistake,\n",
    "    on=[\"Model\", \"prompt_id\", \"Task\", \"objectives\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "\n",
    "df_validity = df_validity.groupby([\"Model\", \"Task\", \"objectives\"])[[\"validity\", \"non-valid-and-numeric\"]].mean().reset_index()\n",
    "df_validity"
   ],
   "id": "b40d3e615001bb41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prop_cls = df_validity[df_validity.objectives == \"classification\"].Task.nunique() / df_validity.Task.nunique()/1.3\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(10,3), gridspec_kw={\"wspace\":0.1, \"width_ratios\": [1-prop_cls, prop_cls]}, sharey=True)\n",
    "\n",
    "for obj, ax in zip([\"regression\", \"classification\"], axes):\n",
    "    df_obj = df_validity[df_validity.objectives == obj]\n",
    "    x_order = df_obj.groupby(\"Task\").validity.mean().sort_values().index.tolist()\n",
    "    df_obj[\"missed\"] = 1- df_obj[\"validity\"]\n",
    "    df_obj[\"missed-and-numeric\"] =1 - df_obj[\"non-valid-and-numeric\"]\n",
    "    kwargs = dict( data=df_obj, x=\"Task\", hue=\"Model\", palette=CMAP_MODELS, order=x_order, ax=ax,)\n",
    "    sns.barplot(\n",
    "        y=\"missed-and-numeric\",\n",
    "        legend=obj == \"classification\",\n",
    "        alpha = 1,\n",
    "        **kwargs\n",
    "    )\n",
    "    sns.barplot(\n",
    "        y=\"missed\",\n",
    "        legend=False,\n",
    "        alpha = 0.4,\n",
    "        **kwargs\n",
    "    )\n",
    "    ax.set_title(obj.capitalize())\n",
    "    _ = ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "    if ax == axes[0]:\n",
    "        ax.set_ylabel(\"Proportion of invalid generations\")\n",
    "    else:\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "fig.savefig(f\"{FIG_PATH}/valid_.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "aa9aa4769f0ebadd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Metric Computation",
   "id": "c27423c037829ece"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Regression",
   "id": "30f5988d88b806ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute Spearman_corr\n",
    "df = full_df[full_df.objectives == \"regression\"]\n",
    "def get_yagg(values):\n",
    "    values = [v for v in values if not np.isnan(v)]\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    return np.mean(values)\n",
    "\n",
    "df[\"y_agg\"] = df.groupby([\"Model\", \"prompt_id\"]).y.transform(get_yagg)\n",
    "correlations = df[df.validity == 1].groupby([\"Model\", \"Task\"])[[\"gt\", \"y_agg\"]].corr(method=\"spearman\").loc[pd.IndexSlice[:, :, \"gt\"], \"y_agg\"]\n",
    "correlations = correlations.reset_index(level=2, drop=True)\n",
    "\n",
    "coverage = df.groupby([\"Model\", \"Task\"]).validity.mean()\n",
    "\n",
    "corr_cov_score = (correlations+1) * coverage / 2\n",
    "corr_cov_score.fillna(0, inplace=True)\n",
    "\n",
    "corr_cov_score"
   ],
   "id": "2c3b3386d70ce8d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Classification",
   "id": "d430120c6c9fa906"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = full_df[full_df.objectives == \"classification\"]\n",
    "\n",
    "def get_yagg(values):\n",
    "    values = [v for v in values if not np.isnan(v)]\n",
    "    if len(values) == 0:\n",
    "        return np.nan\n",
    "    return np.round(np.mean(values) + 1e-8 * values[0]).clip(0,1)\n",
    "\n",
    "df[\"y_agg\"] = df.groupby([\"Model\", \"Task\", \"prompt_id\"]).y.transform(get_yagg)\n",
    "\n",
    "accuracy = df[df.validity == 1].groupby(\n",
    "    [\"Model\", \"Task\"]\n",
    ")[[\"gt\", \"y_agg\"]].apply(\n",
    "    lambda x: np.nanmean((x[\"gt\"]== x[\"y_agg\"]))\n",
    ")\n",
    "coverage = df.groupby([\"Model\", \"Task\"]).validity.mean()\n",
    "accuracy = accuracy * coverage\n",
    "accuracy.fillna(0, inplace=True)\n",
    "\n",
    "accuracy"
   ],
   "id": "e6174962ce804cb7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Add to table",
   "id": "654f55f8ece2329a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Join regression metrics\n",
    "reg_metric = corr_cov_score.reset_index().rename(columns={0: \"Metric\"})\n",
    "cls_metric = accuracy.reset_index().rename(columns={0: \"Metric\"})\n",
    "\n",
    "full_df = full_df.drop(columns=[\"Metric\"], errors=\"ignore\")\n",
    "full_df = full_df.merge(\n",
    "    pd.concat([reg_metric, cls_metric]),\n",
    "    on=[\"Model\", \"Task\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "full_df"
   ],
   "id": "1194a6cc279823fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plots",
   "id": "502769cbdcdbb86f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "KEY = \"Metric\"\n",
    "table = full_df.groupby([\"Model\", \"Task\", \"objectives\"])[KEY].mean().reset_index()\n",
    "MODEL_ORDER = list(CMAP_MODELS.keys())\n",
    "\n",
    "task_order = table.groupby([\"Model\", \"Task\"])[KEY].mean().reset_index().groupby(\"Task\")[KEY].max().sort_values( ascending=False).index\n",
    "\n",
    "table = table.set_index([\"Task\"]).loc[task_order].reset_index()\n",
    "table"
   ],
   "id": "2e7806df03b3cd58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Heatmap",
   "id": "97b2ef583c57ee93"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "MODEL_ORDER = full_df[full_df.objectives == \"regression\"].groupby(\"Model\")[KEY].mean().sort_values().index.tolist()",
   "id": "807cff9d53a4b409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_heatmap(table, axes, title_name, split_val, vmin=0, vmax=1, annot_size=10):\n",
    "    ax = axes[0]\n",
    "    pivoted = pd.pivot_table(table[table.objectives == split_val], KEY, \"Model\", \"Task\")\n",
    "    col_order = pivoted.max().sort_values(ascending=False).index\n",
    "    pivoted = pivoted.loc[MODEL_ORDER,col_order]\n",
    "    sns.heatmap(\n",
    "        pivoted,\n",
    "        ax=ax,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cbar=False,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        annot_kws={\"size\": annot_size}\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xticklabels(rotation=90, ha='center', labels=ax.get_xticklabels())\n",
    "    ax.set_title(title_name)\n",
    "\n",
    "    ax = axes[1]\n",
    "    pivoted = pd.pivot_table(table[table.objectives == split_val], KEY, \"Model\", \"objectives\")\n",
    "    pivoted = pivoted.loc[MODEL_ORDER]\n",
    "    sns.heatmap(\n",
    "        pivoted,\n",
    "        ax=ax,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        cbar=False,\n",
    "        annot=True,\n",
    "        fmt=\".2f\",\n",
    "        annot_kws={\"size\": annot_size}\n",
    "    )\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_xticklabels(rotation=90, ha='center', labels=[\"Avg.\"])\n",
    "    ax.set_title(f\"Avg.\\n{title_name}\")\n"
   ],
   "id": "1b6feb744a38c7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_tot_cols = table.Task.nunique() + 2\n",
    "n_rows = table.Model.nunique()\n",
    "\n",
    "reg_ratio = table[table.objectives == \"regression\"].Task.nunique() / n_tot_cols\n",
    "cls_ratio = table[table.objectives == \"classification\"].Task.nunique() / n_tot_cols\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    1,\n",
    "    4,\n",
    "    figsize = (0.43*n_tot_cols,0.43 * n_rows),\n",
    "    sharey=True,\n",
    "    gridspec_kw = {\n",
    "        \"width_ratios\":[reg_ratio, 1/n_tot_cols, cls_ratio,  1/n_tot_cols],\n",
    "        \"wspace\":0.01,\n",
    "    }\n",
    ")\n",
    "\n",
    "plot_heatmap(table, [axes[0],axes[1]], \"Regression\", \"regression\", annot_size=9)\n",
    "plot_heatmap(table, [axes[2],axes[3]], \"Classification\", \"classification\", vmin = 0.5, vmax=1, annot_size= 9)\n",
    "\n",
    "for ax in axes[1:]:\n",
    "    ax.set_ylabel(\"\")\n",
    "\n",
    "fig.savefig(f\"{FIG_PATH}/molecular_proppred_heatmap.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "2973dc0bc80cb4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Radar Charts",
   "id": "40cb1751d50bcafe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "REMOVE_MODELS = [\n",
    "    # \"ether0\", \"R1-Llama\", \"R1-Qwen\", \"MiniMax-M2\", \"Qwen3\"\n",
    "]\n",
    "TO_HIGHLIGHT = [\n",
    "    \"RL-Mistral\", #\"Qwen3-Next\"\n",
    "]"
   ],
   "id": "96e3c7f00b792ca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Radar charts for classification and regression\n",
    "from math import pi\n",
    "from notebooks.utils import CMAP_MODELS, MARKER_MODELS\n",
    "\n",
    "\n",
    "def plot_radar(ax, table, split_val, title, vmin=0, vmax=1):\n",
    "    model_order = [m for m in CMAP_MODELS.keys() if not m in REMOVE_MODELS and m in table.Model.unique()]\n",
    "    data = pd.pivot_table(table[table.objectives == split_val], KEY, \"Model\", \"Task\")\n",
    "    categories = data.columns.tolist()\n",
    "    n_cats = len(categories)\n",
    "\n",
    "    # Compute angle for each category\n",
    "    angles = [n / float(n_cats) * 2 * pi for n in range(n_cats)]\n",
    "    angles += angles[:1]  # Complete the loop\n",
    "\n",
    "    ax.set_theta_offset(pi / 2)\n",
    "    ax.set_theta_direction(-1)\n",
    "\n",
    "    # Draw category labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(categories, size=8, zorder=120)\n",
    "\n",
    "    # Move labels further from the plot to avoid overlap with grid\n",
    "    ax.tick_params(axis='x', pad=15)\n",
    "\n",
    "    # Draw ylabels\n",
    "    ax.set_rlabel_position(0)\n",
    "    yticks = np.linspace(vmin, vmax, 5)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels([f\"{y:.2f}\" for y in yticks], size=7)\n",
    "    ax.set_ylim(vmin, vmax)\n",
    "\n",
    "    # Plot each model\n",
    "    for model in [m for m in CMAP_MODELS if m in model_order]:\n",
    "        values = data.loc[model].tolist()\n",
    "        values += values[:1]  # Complete the loop\n",
    "        color = CMAP_MODELS.get(model, None)\n",
    "        marker = MARKER_MODELS[model]  # Default to circle if not in MARKER_MODELS\n",
    "        ax.plot(\n",
    "            angles,\n",
    "            values,\n",
    "            linewidth=1.5,\n",
    "            linestyle='solid',\n",
    "            label=model,\n",
    "            color=color,\n",
    "            marker=marker,\n",
    "            markersize=6,\n",
    "            alpha = 1.0 if model in TO_HIGHLIGHT else 0.6\n",
    "        )\n",
    "        ax.fill(angles, values, alpha=0.05, color=color)\n",
    "\n",
    "    ax.set_title(title, size=10, y=1.15)\n",
    "    # Ensure tick labels are drawn on top\n",
    "    for label in ax.get_xticklabels():\n",
    "        label.set_zorder(0)\n",
    "        label.set_bbox(dict(facecolor='white', edgecolor='none', alpha=1., pad=1.))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(9, 4), subplot_kw=dict(polar=True))\n",
    "\n",
    "plot_radar(axes[0], table[~table.Model.isin(REMOVE_MODELS)], \"regression\", \"Regression\", vmin=0, vmax=1)\n",
    "plot_radar(axes[1], table[~table.Model.isin(REMOVE_MODELS)], \"classification\", \"Classification\", vmin=0., vmax=1)\n",
    "\n",
    "# Single legend below both plots\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='lower center', ncol=6, bbox_to_anchor=(0.5, -0.07))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(f\"{FIG_PATH}/molecular_proppred_radar.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ],
   "id": "d9ec17401fa2ad27",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "376babd5f3b57722",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2c2a079636eb20c3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
