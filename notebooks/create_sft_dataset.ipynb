{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from mol_gen_docking.data.pydantic_dataset import read_jsonl, write_jsonl, Sample, Message, Conversation\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "from typing import Dict, Any, List, Tuple, Iterator\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from mol_gen_docking.evaluation.sft_extraction import SFTExtractionConfig, SFTExtractor, Completion"
   ],
   "id": "70c7b91fec3dfbae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SOURCE = \"MiniMax-M2\"\n",
    "DATASET = \"molgendata_train\"\n",
    "PATH = Path(\"MolGenOutput\") / DATASET / SOURCE\n",
    "PROMPT_PATH = Path(f\"data/{DATASET.replace('_train', '')}/train_data/train_prompts_boxed.jsonl\")\n",
    "\n",
    "prompt_dataset = read_jsonl(PROMPT_PATH)\n",
    "\n",
    "comp_dataset = []\n",
    "\n",
    "n_files = len(list(PATH.glob(\"*_scored.jsonl\")))\n",
    "i = 0\n",
    "\n",
    "\n",
    "for path in tqdm(PATH.glob(\"*_scored.jsonl\"), total=n_files):\n",
    "    with jsonlines.open(path) as reader:\n",
    "        for obj in reader:\n",
    "            obj[\"source\"] = SOURCE\n",
    "            obj[\"metadata\"][\"prompt_id\"] = prompt_dataset[i//16].identifier\n",
    "            obj  = Completion.model_validate(obj)\n",
    "            comp_dataset.append(obj)\n",
    "            i+=1\n",
    "\n",
    "print(f\"Extracted {len(comp_dataset)} completions from {n_files} files.\")"
   ],
   "id": "a8568a6b3f171708",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grid_translate(grid: Dict[str, List[Any]]) -> Iterator[SFTExtractionConfig]:\n",
    "    keys, values = zip(*grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        config_dict = {}\n",
    "        for key, value in zip(keys, v):\n",
    "            if not value == \"default\":\n",
    "                config_dict[key] = value\n",
    "        yield SFTExtractionConfig(**config_dict)\n",
    "\n",
    "\n",
    "grid0 = {\n",
    "    \"min_reward_threshold\": [None, 0.2, 0.5],\n",
    "    \"div_threshold\": [None, 0.5, 0.2],\n",
    "    \"reward_info_template\": [{}],\n",
    "    \"source_info_template\": [{}],\n",
    "    \"system_prompt_path\": [\"system_prompts/vanilla_boxed.json\"],\n",
    "}\n",
    "dfs = []\n",
    "for config in grid_translate(grid0):\n",
    "    extractor = SFTExtractor(config)\n",
    "    new_dataset = extractor.extract(comp_dataset, prompt_dataset)\n",
    "    # Save traces\n",
    "    trace_path = Path(\"data/traces\")\n",
    "    for key, value in config.model_dump().items():\n",
    "        trace_path /= f\"{key}_{value}\"\n",
    "    trace_path /= f\"{DATASET}.jsonl\"\n",
    "    trace_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_jsonl(trace_path, new_dataset)\n",
    "    print(f\"N samples extracted for config:\\n === {config.model_dump()} ===\\n**{sum([len(sample.conversations) for sample in new_dataset])}**\")\n",
    "\n",
    "    # Get metadatas\n",
    "    df = pd.DataFrame(extractor.metadata.model_dump())\n",
    "    # Create bins for n_tokens\n",
    "    bins_tokens = [0,1000, 2000, 5000, 7000, 10000, 1e8]\n",
    "    bins_lab = [\"<1k\", \"1k-2k\", \"2k-5k\", \"5k-7k\", \"7k-10k\", \">10k\"]\n",
    "    bins = pd.cut(df[\"n_tokens\"], bins=bins_tokens, right=False, labels=bins_lab)\n",
    "    df[\"n_tokens_bins\"] =bins\n",
    "    df[\"min_reward_threshold\"] = config.min_reward_threshold if config.min_reward_threshold is not None else 0.\n",
    "    df[\"div_threshold\"] = config.div_threshold if config.div_threshold is not None else 1.\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "full_df = pd.concat(dfs).reset_index(drop=True)"
   ],
   "id": "2ff98d959584fe08",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the distribution of the reward\n",
    "df_min = full_df.sort_values(\"rewards\", ascending=True).groupby(\"prompt_ids\").first().reset_index()\n",
    "\n",
    "def prop_plot(\n",
    "        data, **kwargs\n",
    "):\n",
    "    grouped_data = data.groupby([\"prompt_ids\", \"div_threshold\"]).size().sort_values(ascending=False).reset_index().rename(columns={0: \"y\"})\n",
    "    def get_x(sub_df):\n",
    "        return list(range(sub_df.shape[0]))\n",
    "\n",
    "    grouped_data[\"x\"] = grouped_data.groupby(\"div_threshold\").prompt_ids.transform(get_x)\n",
    "    # Plot the distribution of the reward\n",
    "    sns.lineplot(grouped_data, x=\"x\", y=\"y\", hue=\"div_threshold\", **kwargs)\n",
    "\n",
    "\n",
    "facet = sns.FacetGrid(full_df, col=\"min_reward_threshold\", margin_titles=True, sharex=True, sharey=True, height=2.5, aspect=1.8)\n",
    "facet.map_dataframe(\n",
    "    prop_plot\n",
    ")\n",
    "\n",
    "facet.set_titles(col_template=\"$r_m$={col_name}\", row_template=\"$t_d$={row_name}\")\n",
    "# add legend outside of the plot\n",
    "facet.add_legend(title=\"div_threshold\", bbox_to_anchor=(0.9, 0.5), loc=\"center left\")"
   ],
   "id": "f7a7476938ccb363",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the distribution of the reward\n",
    "facet = sns.FacetGrid(full_df, col=\"min_reward_threshold\", row=\"div_threshold\", margin_titles=True, sharex=True, sharey=True, height=1.5, aspect=1.8)\n",
    "facet.map_dataframe(\n",
    "    sns.histplot,\n",
    "    x=\"rewards\",\n",
    "    bins=20,\n",
    "    hue=\"n_tokens_bins\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"flare_r\",\n",
    "    stat=\"probability\",\n",
    "    binwidth=0.1\n",
    ")\n",
    "facet.set_titles(col_template=\"$r_m$={col_name}\", row_template=\"$t_d$={row_name}\")\n"
   ],
   "id": "a1f105d520e1139d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the distribution of the reward\n",
    "df_max = full_df.sort_values(\"rewards\", ascending=False).groupby(\"prompt_ids\").first().reset_index()\n",
    "\n",
    "facet = sns.FacetGrid(df_max, col=\"min_reward_threshold\", row=\"div_threshold\", margin_titles=True, sharex=True, sharey=True, height=1.5, aspect=1.8)\n",
    "facet.map_dataframe(\n",
    "    sns.histplot,\n",
    "    x=\"rewards\",\n",
    "    bins=20,\n",
    "    hue=\"n_tokens_bins\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"flare_r\",\n",
    "    stat=\"probability\",\n",
    "    binwidth=0.1\n",
    ")\n",
    "facet.set_titles(col_template=\"$r_m$={col_name}\", row_template=\"$t_d$={row_name}\")\n"
   ],
   "id": "63454f3a0809690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot the distribution of the reward\n",
    "df_min = full_df.sort_values(\"rewards\", ascending=True).groupby(\"prompt_ids\").first().reset_index()\n",
    "\n",
    "facet = sns.FacetGrid(df_min, col=\"min_reward_threshold\", row=\"div_threshold\", margin_titles=True, sharex=True, sharey=True, height=1.5, aspect=1.8)\n",
    "facet.map_dataframe(\n",
    "    sns.histplot,\n",
    "    x=\"rewards\",\n",
    "    bins=20,\n",
    "    hue=\"n_tokens_bins\",\n",
    "    multiple=\"stack\",\n",
    "    palette=\"flare_r\",\n",
    "    stat=\"probability\",\n",
    "    binwidth=0.1\n",
    ")\n",
    "facet.set_titles(col_template=\"$r_m$={col_name}\", row_template=\"$t_d$={row_name}\")\n"
   ],
   "id": "8cd8e6f9815df9e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid1 = {\n",
    "    \"min_reward_threshold\": [None, 0.2, 0.5],\n",
    "    \"div_threshold\": [None, 0.5, 0.2],\n",
    "    \"reward_info_template\": [\"default\"],\n",
    "    \"source_info_template\": [\"default\"],\n",
    "    \"system_prompt_path\": [\"system_prompts/vanilla_boxed.json\"],\n",
    "}\n",
    "for config in grid_translate(grid1):\n",
    "    extractor = SFTExtractor(config)\n",
    "    new_dataset = extractor.extract(comp_dataset, prompt_dataset)\n",
    "    # Save traces\n",
    "    trace_path = Path(\"data/traces\")\n",
    "    for key, value in config.model_dump().items():\n",
    "        trace_path /= f\"{key}_{value if not isinstance(value, dict) else 'default'}\"\n",
    "    trace_path /= f\"{DATASET}.jsonl\"\n",
    "    trace_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_jsonl(trace_path, new_dataset)\n",
    "    print(f\"N samples extracted for config:\\n === {config.model_dump()} ===\\n**{sum([len(sample.conversations) for sample in new_dataset])}**\")"
   ],
   "id": "e5923fd07a55d0eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d7dfad507b9f5483",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
