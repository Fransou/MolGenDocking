{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from mol_gen_docking.data.pydantic_dataset import read_jsonl, write_jsonl, Sample, Message, Conversation\n",
    "from pathlib import Path\n",
    "import jsonlines\n",
    "from typing import Dict, Any, List, Tuple, Iterator\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from mol_gen_docking.evaluation.sft_extraction import SFTExtractionConfig, SFTExtractor, Completion"
   ],
   "id": "70c7b91fec3dfbae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "SOURCE = \"MiniMax-M2\"\n",
    "DATASET = \"molgendata_train\"\n",
    "PATH = Path(\"MolGenOutput\") / DATASET / SOURCE\n",
    "PROMPT_PATH = Path(f\"data/{DATASET.replace('_train', '')}/train_data/train_prompts_boxed.jsonl\")\n",
    "\n",
    "prompt_dataset = read_jsonl(PROMPT_PATH)\n",
    "\n",
    "comp_dataset = []\n",
    "\n",
    "n_files = len(list(PATH.glob(\"*_scored.jsonl\")))\n",
    "i = 0\n",
    "\n",
    "\n",
    "for path in tqdm(PATH.glob(\"*_scored.jsonl\"), total=n_files):\n",
    "    with jsonlines.open(path) as reader:\n",
    "        for obj in reader:\n",
    "            obj[\"source\"] = SOURCE\n",
    "            obj[\"metadata\"][\"prompt_id\"] = prompt_dataset[i//16].identifier\n",
    "            obj  = Completion.model_validate(obj)\n",
    "            comp_dataset.append(obj)\n",
    "            i+=1\n",
    "\n",
    "print(f\"Extracted {len(comp_dataset)} completions from {n_files} files.\")"
   ],
   "id": "a8568a6b3f171708",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_info(extractor: SFTExtractor) -> plt.Figure:\n",
    "    df = pd.DataFrame(extractor.metadata.model_dump())\n",
    "    # Create bins for n_tokens\n",
    "    bins_tokens = [0,1000, 2000, 5000, 7000, 10000, 1e8]\n",
    "    bins_lab = [\"<1k\", \"1k-2k\", \"2k-5k\", \"5k-7k\", \"7k-10k\", \">10k\"]\n",
    "    bins = pd.cut(df[\"n_tokens\"], bins=bins_tokens, right=False, labels=bins_lab)\n",
    "    df[\"n_tokens_bins\"] =bins\n",
    "\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(16, 3))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    sns.histplot(\n",
    "        data=df, x=\"rewards\", hue=\"n_tokens_bins\", palette = \"flare_r\", multiple=\"stack\", ax=axes[0]\n",
    "    )\n",
    "    axes[0].set_xlabel(\"Reward\")\n",
    "\n",
    "    grouped = df.sort_values(\"rewards\").groupby(\"prompt_ids\").agg({\"rewards\": \"first\", \"n_tokens_bins\": \"first\"}).reset_index()\n",
    "    sns.histplot(\n",
    "        data=grouped, x=\"rewards\", hue=\"n_tokens_bins\", palette = \"flare_r\", multiple=\"stack\", ax=axes[1], legend=False\n",
    "    )\n",
    "    axes[1].set_xlabel(\"Min Reward per Prompt\")\n",
    "\n",
    "    grouped = df.sort_values(\"rewards\", ascending=False).groupby(\"prompt_ids\").agg({\"rewards\": \"first\", \"n_tokens_bins\": \"first\"}).reset_index()\n",
    "    sns.histplot(\n",
    "        data=grouped, x=\"rewards\", hue=\"n_tokens_bins\", palette = \"flare_r\", multiple=\"stack\", ax=axes[2], legend=False\n",
    "    )\n",
    "    axes[2].set_xlabel(\"Max Reward per Prompt\")\n",
    "\n",
    "    grouped = df.groupby(\"prompt_ids\").agg({\"rewards\": \"mean\", \"n_tokens_bins\": lambda x: pd.Series.mode(x)[0]}).reset_index()\n",
    "    sns.histplot(\n",
    "        data=grouped, x=\"rewards\", hue=\"n_tokens_bins\", palette = \"flare_r\", multiple=\"stack\", ax=axes[3], legend=False\n",
    "    )\n",
    "    axes[3].set_xlabel(\"Mean Reward per Prompt\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ],
   "id": "b4ab9e460adfd08f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grid_translate(grid: Dict[str, List[Any]]) -> Iterator[SFTExtractionConfig]:\n",
    "    keys, values = zip(*grid.items())\n",
    "    for v in itertools.product(*values):\n",
    "        config_dict = {}\n",
    "        for key, value in zip(keys, v):\n",
    "            if not value == \"default\":\n",
    "                config_dict[key] = value\n",
    "        yield SFTExtractionConfig(**config_dict)\n",
    "\n",
    "\n",
    "grid0 = {\n",
    "    \"min_reward_threshold\": [None, 0.2, 0.5],\n",
    "    \"div_threshold\": [None, 0.5],\n",
    "    \"reward_info_template\": [{}],\n",
    "    \"source_info_template\": [{}],\n",
    "}\n",
    "\n",
    "for config in grid_translate(grid0):\n",
    "    extractor = SFTExtractor(config)\n",
    "    new_dataset = extractor.extract(comp_dataset, prompt_dataset)\n",
    "    fig = plot_info(extractor)\n",
    "    fig.suptitle(f\"{name}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    # Save traces\n",
    "    trace_path = Path(\"data/traces\")\n",
    "    for key, value in config.model_dump().items():\n",
    "        trace_path /= f\"{key}_{value}\"\n",
    "    trace_path /= f\"{DATASET}.jsonl\"\n",
    "    trace_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    write_mport load_dataset\n",
    "    jsonl(trace_path, new_dataset)"
   ],
   "id": "2ff98d959584fe08",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
