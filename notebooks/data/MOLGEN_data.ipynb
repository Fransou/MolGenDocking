{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%cd ..\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "a3fa849b551cd4e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from mol_gen_docking.data.pdb_uniprot.target_naming import fetch_uniprot_id_from_pdbid\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tqdm.pandas()"
   ],
   "id": "5d701ee9a7d07a38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Targets",
   "id": "f1ed4efe4016d3c7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_all_cols(df, N_COLS, fig, escape=[\"smiles\", \"pdb_id\"]):\n",
    "    outer_grid = fig.add_gridspec(N_COLS, 1, wspace=0.1, hspace=0.5)\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    n_cols = (df[[c for c in df.columns if not c in escape]].shape[1]-1) // N_COLS +1\n",
    "\n",
    "    grid = outer_grid[0].subgridspec(1, ncols=n_cols)\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col not in escape:\n",
    "            ax = plt.subplot(grid[i])\n",
    "            sns.histplot(df[col], bins=100, ax=ax)\n",
    "            ax.set_title(col)\n",
    "            i += 1\n",
    "            if i == n_cols and not j == N_COLS - 1:\n",
    "                i = 0\n",
    "                j += 1\n",
    "                if j == N_COLS - 1:\n",
    "                    grid = outer_grid[j].subgridspec(1, ncols=n_cols + (df[[c for c in df.columns if not c in escape]].shape[1]-1) % N_COLS)\n",
    "                else:\n",
    "                    grid = outer_grid[j].subgridspec(1, ncols=n_cols)\n",
    "\n",
    "# df = pd.read_csv(\"data/properties.csv\", index_col=0)\n",
    "# fig = plt.figure(figsize=(20, 10))\n",
    "# plot_all_cols(df, 4, fig, escape=[\"smiles\", \"pdb_id\"])"
   ],
   "id": "f3c2ffa3748889e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATA_PATH = \"data/molgendata\"\n",
    "with open(os.path.join(DATA_PATH, \"pockets_info.json\")) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with open(os.path.join(DATA_PATH, \"docking_targets.json\")) as f:\n",
    "    targ = json.load(f)\n",
    "\n",
    "data = {k: data[k][\"metadata\"] for k in data if k in targ}\n",
    "target_info = pd.DataFrame.from_dict(data).transpose()\n",
    "target_info[\"origin\"] = target_info[\"origin\"].fillna(\"sair\")\n",
    "\n",
    "target_info[\"volume (nm$^3$)\"] = target_info[\"size\"].apply(lambda x: np.prod(x)/1000)\n",
    "\n",
    "def get_activity_val(row: pd.Series):\n",
    "    if not np.isnan(row.avg_pIC50):\n",
    "        return row.avg_pIC50\n",
    "    else:\n",
    "        return row.avg_pKd\n",
    "\n",
    "def get_activity_label(row: pd.Series):\n",
    "    if not np.isnan(row.avg_pIC50):\n",
    "        return \"pIC50\"\n",
    "    else:\n",
    "        return \"pKd\"\n",
    "\n",
    "target_info[\"Average labeled activity\"] = target_info.apply(get_activity_val, axis=1)\n",
    "target_info[\"activity unit\"] = target_info.apply(get_activity_label, axis=1)\n",
    "target_info = target_info.sort_values(\"prot_id\", ascending=False)\n",
    "target_info"
   ],
   "id": "b21386f02bb22248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(6, 2), )\n",
    "axes = axes.flatten()\n",
    "\n",
    "plt.subplots_adjust(wspace=0.4)\n",
    "axes = axes.flatten()\n",
    "cols = [(\"volume (nm$^3$)\",\"origin\"), (\"Average labeled activity\", \"activity unit\")]\n",
    "palette = sns.color_palette(\"Paired\", n_colors=2)[::-1]\n",
    "\n",
    "for ax, col in zip(axes, cols):\n",
    "    if len(col) == 1:\n",
    "        sns.histplot(target_info, x=col[0], bins=20, hue=col[1], ax=ax, multiple=\"stack\", palette=palette)\n",
    "    else:\n",
    "        sns.histplot(target_info, x=col[0], bins=20, ax=ax, hue=col[1], multiple=\"stack\", palette=palette)\n",
    "\n"
   ],
   "id": "ba95c7fcbd1c87a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "(20*10**-10)**3 / 10**-27\n",
    "\n"
   ],
   "id": "b221a2ac1e6c934",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import requests\n",
    "\n",
    "def get_info(uniprot_id):\n",
    "    try:\n",
    "        url = f\"https://rest.uniprot.org/uniprotkb/{uniprot_id}.json\"\n",
    "        response = requests.get(url, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            raise ValueError(f\"UniProt ID {uniprot_id} not found.\")\n",
    "        data = response.json()\n",
    "        data[\"organism\"] = data.get(\"organism\", {})\n",
    "        prt_ex = None\n",
    "        if \"proteinExistence\" in data:\n",
    "            prt_ex = data[\"proteinExistence\"]\n",
    "        elif \"inactiveReason\" in data:\n",
    "            prt_ex = data[\"inactiveReason\"][\"deletedReason\"]\n",
    "        else:\n",
    "            prt_ex = \"5: Uncertain\"\n",
    "        out = dict(\n",
    "            molecular_func = \"unknown\",\n",
    "            uniprot_score = data[\"annotationScore\"],\n",
    "            organism= data[\"organism\"].get(\"scientificName\", \"unk\"),\n",
    "            proteinExistence= prt_ex,\n",
    "            organism_path=data[\"organism\"].get(\"lineage\", np.nan),\n",
    "            len_lineage=len(data[\"organism\"].get(\"lineage\", [])),\n",
    "        )\n",
    "        mol_func = []\n",
    "        if \"keywords\" in data:\n",
    "            for kyw in data[\"keywords\"]:\n",
    "                if kyw[\"category\"] == \"Molecular function\":\n",
    "                    mol_func.append(kyw[\"name\"])\n",
    "            out[\"molecular_func\"] = mol_func\n",
    "        else:\n",
    "            out[\"molecular_func\"] = \"unk\"\n",
    "    except Exception as e:\n",
    "        return None\n",
    "    return out"
   ],
   "id": "911f130451daf083",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "get_info(target_info.prot_id[0])",
   "id": "d09936e239a9a259",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "pool = Pool(64)\n",
    "uniprot_ids = target_info[\"prot_id\"].unique()\n",
    "infos = {\n",
    "    uniprot_id: inf for uniprot_id, inf in zip(\n",
    "        uniprot_ids,\n",
    "        list(\n",
    "            tqdm(\n",
    "                pool.imap(get_info, uniprot_ids),\n",
    "                total=len(uniprot_ids)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "}\n",
    "del pool"
   ],
   "id": "71cc9385e60457d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "failed = [k for k in infos if infos[k] is None]\n",
    "print(len(failed))\n",
    "pool = Pool(16)\n",
    "uniprot_ids = failed\n",
    "new_infos = {\n",
    "    uniprot_id: inf for uniprot_id, inf in zip(\n",
    "        uniprot_ids,\n",
    "        list(\n",
    "            tqdm(\n",
    "                pool.imap(get_info, uniprot_ids),\n",
    "                total=len(uniprot_ids)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "}\n",
    "for unip, v in new_infos.items():\n",
    "    if v is not None:\n",
    "        infos[unip] = v\n",
    "\n",
    "del pool\n"
   ],
   "id": "ca27ae9874e1c7c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for k in list(infos[list(infos.keys())[0]].keys()):\n",
    "    target_info[k] = target_info[\"prot_id\"].apply(lambda id: infos[id][k])\n"
   ],
   "id": "bd6dc5be5bfbcf01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target_info.to_csv(\"data/tmp.csv\")",
   "id": "47d4cdfedfd295c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "target_info_df = pd.read_csv(\"data/tmp.csv\")\n",
    "def decode_org(org_path):\n",
    "    if isinstance(org_path, str) and not org_path==\"unk\":\n",
    "        return json.loads(org_path.replace(\"'\",'''\"'''))\n",
    "    return org_path\n",
    "\n",
    "target_info_df.organism_path = target_info_df.organism_path.apply(decode_org)\n",
    "target_info_df.molecular_func = target_info_df.molecular_func.apply(decode_org)\n"
   ],
   "id": "f42b7470f29e37dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target_info_df",
   "id": "621b8e735a7a34db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Re arrange path for lineage\n",
    "\n",
    "lineage_max = target_info_df[\"len_lineage\"].max()\n",
    "\n",
    "def get_lineage(df, idx_forb):\n",
    "    lineage_df = df[[\"prot_id\", \"organism\", \"organism_path\", \"len_lineage\"]]\n",
    "    lineage_df[\"organism_path\"] = lineage_df[\"organism_path\"].apply(lambda L: [L[i] for i in range(len(L)) if not i in idx_forb or i == len(L) - 1])\n",
    "\n",
    "\n",
    "    leaf_list = [L[-1] for L in lineage_df[\"organism_path\"]]\n",
    "    lineage_df[\"leaf_reached\"] = False\n",
    "    for k in range(lineage_max+1):\n",
    "        lineage_df[\"lineage_{}\".format(k)] = lineage_df.apply(\n",
    "            lambda row: None if len(row[\"organism_path\"]) <= k or row[\"leaf_reached\"] else row[\"organism_path\"][k],\n",
    "            axis=1\n",
    "        )\n",
    "        lineage_df[\"leaf_reached\"] = lineage_df.apply(lambda row: row[\"leaf_reached\"] or row[\"lineage_{}\".format(k)] in leaf_list, axis=1)\n",
    "\n",
    "    lineage_df[\"org_path_hash\"] = lineage_df.apply(lambda row: \"\".join([row[\"lineage_{}\".format(k)] for k in range(lineage_max) if not row[\"lineage_{}\".format(k)] is None]), axis=1)\n",
    "\n",
    "    count_organism = lineage_df.groupby(\"org_path_hash\").prot_id.nunique().to_frame().rename(columns={\"prot_id\": \"organism_count\"})\n",
    "\n",
    "    lineage_df = lineage_df.join(count_organism, on=\"org_path_hash\")\n",
    "    lineage_df = lineage_df.drop([\"prot_id\", \"organism_path\", \"organism\", \"len_lineage\"], axis=1).drop_duplicates()\n",
    "    return lineage_df"
   ],
   "id": "a8c92f165355d95c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lineage_df = get_lineage(target_info_df[~target_info_df.organism_path.isna()], [1,2,3,4,5,7,8] + list(range(10,lineage_max+1)))\n",
    "fig = px.sunburst(lineage_df, path=[f\"lineage_{k}\" for k in range(15)], values='organism_count', width=600, height=600,)\n",
    "fig.update_layout(\n",
    "    font=dict(size=20),\n",
    "    )\n",
    "fig.show()"
   ],
   "id": "a529aee0233056",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "52790242d4c577db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fn_count = {}\n",
    "target_info_df.molecular_func = target_info_df.molecular_func.apply(lambda x: [x] if not isinstance(x, list) else x)\n",
    "for mol_fns in target_info_df.molecular_func:\n",
    "    for fn in mol_fns:\n",
    "        fn_count[fn] = fn_count.get(fn, 0) + 1\n",
    "\n",
    "max_len_func = target_info_df.molecular_func.apply(len).max()\n",
    "taxonomy: dict[str,str] = {} # Parent -> Child\n",
    "for iteration in tqdm(range(max_len_func)):\n",
    "    for mol_fns in target_info_df.molecular_func:\n",
    "        if len(mol_fns) < iteration + 1:\n",
    "            continue\n",
    "        # Get largest parent not already in taxonomy\n",
    "        ordered_mol_fns = sorted(mol_fns, key=fn_count.get)[::-1]\n",
    "        for i in range(len(ordered_mol_fns)-1):\n",
    "            if not ordered_mol_fns[i] in taxonomy:\n",
    "                taxonomy[ordered_mol_fns[i]] = ordered_mol_fns[i+1]\n",
    "                break\n",
    "\n",
    "len(taxonomy), len(fn_count)"
   ],
   "id": "b262d2d325704833",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "counts = fn_count",
   "id": "68bee46d0ac2e59d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "child_to_parent = {child: parent for parent, child in taxonomy.items()}\n",
    "\n",
    "def build_path(leaf):\n",
    "    path = [leaf]\n",
    "    while path[-1] in child_to_parent:\n",
    "        path.append(child_to_parent[path[-1]])\n",
    "    return path[::-1]  # reverse to have root -> leaf\n",
    "\n",
    "# Build DataFrame for all leaves (all nodes in counts)\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for node in counts.keys():\n",
    "    path = build_path(node)\n",
    "    rows.append(path + [counts[node]])  # add count as last column\n",
    "\n",
    "# Determine the max depth\n",
    "max_depth = max(len(r) for r in rows)\n",
    "\n",
    "# Pad paths to same length for DataFrame\n",
    "for r in rows:\n",
    "    while len(r) < max_depth + 1:\n",
    "        r.insert(-1, np.nan)  # insert empty strings before count\n",
    "\n",
    "# Column names: Level1, Level2, ..., Count\n",
    "col_names = [f\"level{i+1}\" for i in range(max_depth)] + [\"count\"]\n",
    "\n",
    "df = pd.DataFrame(rows, columns=col_names)\n",
    "\n",
    "def get_longest_path(df, value):\n",
    "    return (~df[df[\"level1\"] == value].isna()).sum(1).max() - 2\n",
    "\n",
    "for value in df.level1.unique():\n",
    "    length = get_longest_path(df, value)\n",
    "    for i in range(df.shape[0]):\n",
    "        for depth in range(2,length+2):\n",
    "            if df.level1[i] == value and df[f\"level{depth}\"].isna()[i] and df[f\"level{depth-1}\"][i] != \"\" and ~df[f\"level{depth-1}\"].isna()[i]:\n",
    "                df[f\"level{depth}\"].iloc[i] = \"\"\n",
    "\n",
    "\n",
    "df\n"
   ],
   "id": "b75ea0f4701084da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "50a88666dfee28ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.graph_objects as go\n",
    "parents = []\n",
    "children = []\n",
    "labels = []\n",
    "\n",
    "for val in df.level1.unique():\n",
    "    parents.append(\"\")\n",
    "    children.append(val)\n",
    "    labels.append(counts[val])\n",
    "\n",
    "for lvl in range(2,5):\n",
    "    for val in df[f\"level{lvl}\"].unique():\n",
    "        if not val in [np.nan, \"\"]:\n",
    "            parent = df[df[f\"level{lvl}\"] == val][f\"level{lvl-1}\"].iloc[0]\n",
    "            parents.append(parent)\n",
    "            children.append(val)\n",
    "            labels.append(counts[val])\n",
    "\n",
    "\n",
    "fig =px.sunburst(\n",
    "        names=children,\n",
    "        parents=parents,\n",
    "        values=labels, width=800, height=800\n",
    ")\n",
    "fig.update_layout(\n",
    "    font=dict(size=20),\n",
    "    )\n",
    "\n",
    "fig.show()"
   ],
   "id": "d6c70f62328de2b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = t(\n",
    "    df,\n",
    "    path=[f\"level{i+1}\" for i in range(2)],\n",
    "    values=\"count\",\n",
    "    width=800,\n",
    "    height=800,\n",
    ")\n",
    "fig.show()"
   ],
   "id": "aa321fae87a5e834",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4a1cfd10cfa1f148",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig,ax = plt.subplots(1,1,figsize=(4,3))\n",
    "target_info_df[\"Protein existence\"] = target_info_df.proteinExistence.apply(lambda x: x if \":\" in x else \"5: Uncertain\")\n",
    "order = target_info_df.molecular_func.value_counts().sort_values()[::-1].index.tolist()[:10]\n",
    "\n",
    "target_info_df.rename(columns={\"uniprot_score\": \"Annotation Score\"}, inplace=True)\n",
    "target_info_df[\"Annotation Score\"] = pd.Categorical(target_info_df[\"Annotation Score\"], [1.,2.,3.,4.,5.])\n",
    "\n",
    "\n",
    "palette = {\n",
    "    k: sns.color_palette(\"coolwarm\", as_cmap=True)((int(k.split(':')[0])-1)/4) for k in target_info_df[\"Protein existence\"].unique()\n",
    "}\n",
    "\n",
    "sns.histplot(data = target_info_df.sort_values(\"Protein existence\", ascending=True), x = \"Annotation Score\", hue=\"Protein existence\", multiple=\"stack\", ax=ax, palette=palette, binwidth=.2)\n",
    "ax.set_xlabel(\"\")\n",
    "sns.move_legend(\n",
    "    ax, \"upper left\",\n",
    " ncol=1,fontsize=9\n",
    ")\n",
    "ax.tick_params(axis=\"x\", rotation=90)\n",
    "# plt.yscale(\"log\")\n",
    "\n",
    "plt.savefig(\"target_mol_fn.png\", dpi=300, bbox_inches=\"tight\")"
   ],
   "id": "c0ec477f500e76ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "target_info_df.molecular_func.unique().tolist()",
   "id": "8a941e204233b932",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prompts",
   "id": "5543430f7c9981a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from mol_gen_docking.data.pydantic_dataset import read_jsonl\n",
    "from pathlib import Path\n",
    "\n",
    "def load(path:str):\n",
    "    data = read_jsonl(Path(path))\n",
    "    return [line.conversations[0].meta for line in data]\n",
    "\n",
    "data_dir = \"data/molgendata\"\n",
    "with open(os.path.join(data_dir, \"pockets_info.json\")) as f:\n",
    "    pockets = json.load(f)\n",
    "with open(os.path.join(data_dir, \"docking_targets.json\")) as f:\n",
    "    docking_targets = json.load(f)\n",
    "\n",
    "data = {}\n",
    "for d in os.listdir(os.path.join(data_dir)):\n",
    "    directory = os.path.join(data_dir, d)\n",
    "    if d.endswith(\".jsonl\"):\n",
    "        data[d.split(\".\")[0]] = load(Path(directory))\n",
    "    if os.path.isdir(directory):\n",
    "        for f in os.listdir(directory):\n",
    "            if f.endswith(\".jsonl\"):\n",
    "                data[f.split(\".\")[0]] = load(Path(os.path.join(directory, f)))\n"
   ],
   "id": "e026221017a2ab0d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def transf(x):\n",
    "    if x in pockets:\n",
    "        return \"docking\"\n",
    "    return x.replace(\"Calc\", \"\").replace(\"Bonds\", \"B.\").replace(\"Rings\", \"R.\")\n",
    "\n",
    "def get_df(data_d):\n",
    "    df = pd.DataFrame(data_d)\n",
    "    df = df.drop(columns=[\"docking_metadata\"])\n",
    "    df= df.explode([\"properties\", \"objectives\", \"target\"]).reset_index(drop=True)\n",
    "    df[\"is_docking\"] = df[\"properties\"].apply(lambda x: x in docking_targets)\n",
    "\n",
    "    df[\"reward_type\"] = df.properties.apply(transf)\n",
    "    return df\n"
   ],
   "id": "94935c22cdd829b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data.keys()",
   "id": "a3adec5457f3b6a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = get_df(data[\"train_prompts\"])\n",
    "df"
   ],
   "id": "133131a7728fce26",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.prompt_id.nunique()",
   "id": "5235daf1153d49a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"obj_count\"] = df.n_props.apply(lambda x: 1/x)\n",
    "\n",
    "df.groupby(\"objectives\").obj_count.sum()\n"
   ],
   "id": "afa477188c041716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ks = [\"test_prompts_ood\"]\n",
    "df = pd.concat([get_df(data[k]) for k in ks]).reset_index(drop=True)\n",
    "palette = {\n",
    "    \"below\": sns.color_palette(\"Paired\", n_colors = 6)[0],\n",
    "    \"minimize\": sns.color_palette(\"Paired\", n_colors = 6)[1],\n",
    "    \"above\":sns.color_palette(\"Paired\", n_colors = 6)[4],\n",
    "    \"maximize\":sns.color_palette(\"Paired\", n_colors = 6)[5],\n",
    "}\n",
    "order = df.groupby(\"reward_type\").count().sort_values(\"prompt_id\").index[::-1]\n",
    "df[\"reward_type\"] = pd.Categorical(df[\"reward_type\"], categories=order)\n",
    "fig, ax = plt.subplots(1,1, figsize=(2,4))\n",
    "\n",
    "_ = sns.histplot(df, y=\"reward_type\", hue = \"objectives\",  palette=palette, multiple = \"stack\", stat=\"proportion\", ax=ax)\n",
    "labels = ax.get_xticklabels()\n",
    "ax.set_xlabel(\"\")\n",
    "ax.grid(False)\n",
    "ax.set_xlabel(\"Proportion\")\n",
    "ax.set_ylabel(\"\")\n",
    "fig.savefig(\"../-Philippe-MolGenDocking/Figures/generation_data/reward_type.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "ffb8da2b99212ace",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def reward_combinations(sub_df):\n",
    "    all_rewards = sub_df[\"reward_type\"].tolist()\n",
    "    n_docking = sub_df[\"is_docking\"].sum()\n",
    "    out = \"\"\n",
    "    if \"docking\" in all_rewards:\n",
    "        if n_docking > 1:\n",
    "            if len(all_rewards) == 2:\n",
    "                return \"2-docking\"\n",
    "            return \"2-docking + ...\"\n",
    "        else:\n",
    "            out += \"docking + \"\n",
    "    elif len(all_rewards) == 1:\n",
    "        return \"other\"\n",
    "    if \"QED\" in all_rewards:\n",
    "        out += \"QED + \"\n",
    "    if \"SA\" in all_rewards:\n",
    "        out += \"SA + \"\n",
    "\n",
    "    for r in all_rewards:\n",
    "        if not r in [\"docking\", \"QED\", \"SA\"]:\n",
    "            out += \"other + \"\n",
    "    if out == \"\":\n",
    "        raise ValueError(all_rewards)\n",
    "    return out[:-3]\n"
   ],
   "id": "99ea581de0b813b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ks = [\"test_prompts_ood\"]\n",
    "df = pd.concat([get_df(data[k]) for k in ks]).reset_index(drop=True).iloc[:500]\n",
    "\n",
    "df_ragg = df.groupby([\"prompt_id\", \"n_props\"]).apply(reward_combinations).to_frame().rename(columns={0:\"p\"})\n",
    "df_ragg = df_ragg.groupby(\"n_props\").p.value_counts()/df_ragg.groupby(\"n_props\").p.count()\n",
    "df_ragg = df_ragg.reset_index()\n",
    "df_ragg = df_ragg.rename(\n",
    "    columns={\n",
    "        \"p\": \"type\", 0: \"proportion\"\n",
    "    }\n",
    ")\n"
   ],
   "id": "edc6a08be1c54d56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "proportions_n_props = df.groupby(\"n_props\").prompt_id.nunique() / df.groupby(\"n_props\").prompt_id.nunique().sum()",
   "id": "32a804fe45ef60d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. DATA PREPARATION\n",
    "df_csv = df_ragg\n",
    "\n",
    "# Calculate inner proportions (Replace this with your original df.groupby logic if needed)\n",
    "# Here I use placeholder values matching your draft\n",
    "inner_proportions = {\n",
    "    '1 Property': proportions_n_props[1],\n",
    "    '2 Properties': proportions_n_props[2],\n",
    "    '3 Properties': proportions_n_props[3]\n",
    "}\n",
    "\n",
    "# 2. COLOR PALETTE DEFINITION\n",
    "# We use colormaps to generate matching shades for subgroups\n",
    "cmaps = [plt.cm.Blues, plt.cm.Greens, plt.cm.Oranges]\n",
    "inner_colors = [cmaps[0](0.6), cmaps[1](0.6), cmaps[2](0.6)]\n",
    "\n",
    "outer_sizes = []\n",
    "outer_labels = []\n",
    "outer_colors = []\n",
    "outer_relative_pct = []\n",
    "\n",
    "for i, (group_name, inner_p) in enumerate(inner_proportions.items()):\n",
    "    n = int(group_name.split()[0])\n",
    "    sub_df = df_csv[df_csv['n_props'] == n].sort_values('proportion', ascending=False)\n",
    "\n",
    "    for j, (_, row) in enumerate(sub_df.iterrows()):\n",
    "        outer_sizes.append(row['proportion'] * inner_p)\n",
    "        outer_labels.append(row['type'])\n",
    "        outer_relative_pct.append(row['proportion'] * 100)\n",
    "        # Create shades: darker for the largest subgroup, lighter for the others\n",
    "        shade = 0.7 - (j / (len(sub_df) + 1)) * 0.4\n",
    "        outer_colors.append(cmaps[i](shade))\n",
    "\n",
    "# 3. PLOTTING\n",
    "fig, ax = plt.subplots(figsize=(12, 12), dpi=100)\n",
    "\n",
    "# Outer Ring\n",
    "wedges_out, _ = ax.pie(\n",
    "    outer_sizes, radius=1, colors=outer_colors,\n",
    "    startangle=60, counterclock=False,\n",
    "    wedgeprops=dict(width=0.25, edgecolor='white', linewidth=1.5)\n",
    ")\n",
    "# 1. Define Geometry\n",
    "inner_rad = 0.7\n",
    "inner_w = 0.3\n",
    "inner_label_pos = (inner_rad - inner_w/2) / inner_rad *0.8\n",
    "# Inner Ring\n",
    "wedges_in, texts_in = ax.pie(\n",
    "    list(inner_proportions.values()),\n",
    "    labels=list(inner_proportions.keys()),\n",
    "    radius=inner_rad, colors=inner_colors,\n",
    "    startangle=60, counterclock=False,\n",
    "    labeldistance=inner_label_pos,\n",
    "    textprops={'color': 'white', 'weight': 'bold', 'fontsize': 10},\n",
    "    wedgeprops=dict(width=inner_w, edgecolor='w', linewidth=2)\n",
    ")\n",
    "\n",
    "# 4. PRETTIFY LABELS (Callouts for the outer ring)\n",
    "for i, p in enumerate(outer_sizes):\n",
    "    # Only label segments larger than 1.5% to prevent clutter\n",
    "    if (p / sum(outer_sizes)) > 0.01:\n",
    "        # Calculate angle for the center of the wedge\n",
    "        ang = (wedges_out[i].theta2 + wedges_out[i].theta1) / 2.\n",
    "        y = np.sin(np.deg2rad(ang))\n",
    "        x = np.cos(np.deg2rad(ang))\n",
    "\n",
    "        # Alignment based on which side of the circle we are on\n",
    "        horizontalalignment = {-1: \"right\", 1: \"left\"}[int(np.sign(x))]\n",
    "\n",
    "        # Draw line and text\n",
    "        ax.annotate(f\"{outer_labels[i]}\\n({outer_relative_pct[i]:.1f}%)\",\n",
    "                    xy=(x, y), xytext=(1.1*x, 1.1*y),\n",
    "                    horizontalalignment=horizontalalignment,\n",
    "                    fontsize=10, fontweight='medium',\n",
    "                    arrowprops=dict(arrowstyle=\"-\", color=\"#555555\", connectionstyle=\"arc3,rad=0\"))\n",
    "\n",
    "# Central Decoration\n",
    "ax.text(0, 0, 'Optimization\\nObjectives', ha='center', va='center',\n",
    "        fontsize=15, weight='bold', color='#444444')\n",
    "\n",
    "plt.title(\"Hierarchical Distribution of Prompt Types\", fontsize=18, pad=30, weight='bold')\n",
    "ax.set(aspect=\"equal\")\n",
    "\n",
    "plt.savefig('nested_donut_final.png', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "c42fa3080056d715",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Prepare Data\n",
    "df_csv = df_ragg\n",
    "\n",
    "# Proportions (Replace with your actual 'props' calculation)\n",
    "inner_proportions = {\n",
    "    '1 Property': proportions_n_props[1],\n",
    "    '2 Properties': proportions_n_props[2],\n",
    "    '3 Properties': proportions_n_props[3]\n",
    "}\n",
    "# 2. Setup Plotting Parameters\n",
    "cmaps = [plt.cm.Blues, plt.cm.Greens, plt.cm.Oranges]\n",
    "inner_colors = [cmaps[0](0.6), cmaps[1](0.6), cmaps[2](0.6)]\n",
    "sketch_style = (0.7, 100, 1.2) # scale, length, randomness\n",
    "\n",
    "outer_sizes, outer_labels, outer_colors, outer_relative_pct = [], [], [], []\n",
    "\n",
    "for i, (name, inner_p) in enumerate(inner_proportions.items()):\n",
    "    n = int(name.split()[0])\n",
    "    sub_df = df_csv[df_csv['n_props'] == n].sort_values('proportion', ascending=False)\n",
    "    for j, (_, row) in enumerate(sub_df.iterrows()):\n",
    "        outer_sizes.append(row['proportion'] * inner_p)\n",
    "        outer_labels.append(row['type'])\n",
    "        outer_relative_pct.append(row['proportion'] * 100)\n",
    "        outer_colors.append(cmaps[i](0.7 - (j / (len(sub_df) + 1)) * 0.4))\n",
    "\n",
    "# 3. Create Figure\n",
    "fig, ax = plt.subplots(figsize=(6, 6), facecolor='none')\n",
    "\n",
    "# 4. Draw Rings\n",
    "# Outer Ring\n",
    "wedges_out, _ = ax.pie(outer_sizes, radius=1.0, colors=outer_colors,\n",
    "                       startangle=20, counterclock=False,\n",
    "                       wedgeprops=dict(width=0.25, edgecolor='black', linewidth=1.5))\n",
    "\n",
    "# Inner Ring\n",
    "inner_rad, inner_w = 0.7, 0.3\n",
    "inner_label_pos = (inner_rad - inner_w/2) / inner_rad * 0.8\n",
    "wedges_in, texts_in = ax.pie(list(inner_proportions.values()),\n",
    "                             radius=inner_rad, colors=inner_colors,\n",
    "                             startangle=20, counterclock=False,\n",
    "                             labeldistance=inner_label_pos,\n",
    "                             textprops={'color': 'black', 'weight': 'bold', 'fontsize': 11},\n",
    "                             wedgeprops=dict(width=inner_w, edgecolor='black', linewidth=2))\n",
    "\n",
    "# Apply the \"Sloppy\" sketch filter to all wedges\n",
    "for w in wedges_out + wedges_in:\n",
    "    w.set_sketch_params(*sketch_style)\n",
    "\n",
    "# 5. Add Annotations with Sloppy Arrows\n",
    "for i, p in enumerate(outer_sizes):\n",
    "    if (p / sum(outer_sizes)) > 0.01:\n",
    "        ang = (wedges_out[i].theta2 + wedges_out[i].theta1) / 2.\n",
    "        y, x = np.sin(np.deg2rad(ang)), np.cos(np.deg2rad(ang))\n",
    "        ha = \"left\" if x > 0 else \"right\"\n",
    "\n",
    "        ann = ax.annotate(f\"{outer_labels[i]} ({outer_relative_pct[i]:.1f}%)\",\n",
    "                          color=\"black\",\n",
    "                          xy=(x, y), xytext=(1.1*x, 1.1*y),\n",
    "                          horizontalalignment=ha, fontsize=9,\n",
    "                          arrowprops=dict(arrowstyle=\"-\", color=\"black\",\n",
    "                                          connectionstyle=\"arc3,rad=0.1\", linewidth=1.2))\n",
    "        ann.arrow_patch.set_sketch_params(*sketch_style)\n",
    "\n",
    "ax.set(aspect=\"equal\")\n",
    "\n",
    "leg = ax.legend(wedges_in, inner_proportions.keys(),\n",
    "                title=\"Number of prop.\\n to optimize\",\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(.9, 0.5), # Positions it to the right of the plot\n",
    "                labelcolor='black',  # Sets all text to black\n",
    "                fontsize=10, title_fontsize=10,\n",
    "                frameon=False)\n",
    "leg.get_title().set_color('#4A4A4A')  # A nice dark grey\n",
    "leg.get_title().set_weight('bold')\n",
    "\n",
    "# 2. Make the legend boxes \"sloppy\" to match the plot\n",
    "# for patch in leg.get_patches():\n",
    "#     patch.set_sketch_params(*sketch_style)\n",
    "\n",
    "# Save with transparent background\n",
    "plt.savefig('../-Philippe-MolGenDocking/Figures/generation_data/donut_dataset.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ],
   "id": "6dbfb3eab5d47e2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "inner_proportions",
   "id": "b84b4408cf3196e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.histplot(df, hue=\"reward_type\", x=\"n_props\", alpha=1, multiple=\"fill\", palette=sns.color_palette(\"colorblind\"))\n",
    "plt.xticks(rotation=90)"
   ],
   "id": "729e4f13bd82a216",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby()",
   "id": "742b782fdf0d2053",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "!ls ../-Philippe-MolGenDocking/Figures\n",
   "id": "53e33e29357215c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "260393e48e58fd43",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
